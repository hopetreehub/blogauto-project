#!/usr/bin/env python3
"""
í”„ë¡œë•ì…˜ ë°°í¬ ì¤€ë¹„ ìƒíƒœ ìµœì¢… ê²€ì¦
Step 12: ëª¨ë“  ì‹œìŠ¤í…œ êµ¬ì„±ìš”ì†Œì˜ í”„ë¡œë•ì…˜ ì¤€ë¹„ë„ í‰ê°€
"""

import asyncio
import aiohttp
import json
import time
import subprocess
import os
import sys
from datetime import datetime
from typing import Dict, Any, List
from pathlib import Path

class ProductionReadinessChecker:
    def __init__(self):
        self.base_url = "http://localhost:8000"
        self.session = None
        self.check_results = {}
        self.critical_issues = []
        self.warnings = []
        self.recommendations = []
        
    async def __aenter__(self):
        timeout = aiohttp.ClientTimeout(total=30)
        self.session = aiohttp.ClientSession(timeout=timeout)
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def check_api_functionality(self) -> Dict[str, Any]:
        """API ê¸°ëŠ¥ ì™„ì „ì„± ê²€ì¦"""
        print("ğŸ¯ API ê¸°ëŠ¥ ì™„ì „ì„± ê²€ì¦...")
        
        results = {}
        
        # 1. ê¸°ë³¸ ì„œë²„ ì‘ë‹µ
        try:
            async with self.session.get(f"{self.base_url}/") as response:
                results["server_root"] = {
                    "status": response.status,
                    "working": response.status == 200,
                    "response_time": 0
                }
                if response.status == 200:
                    data = await response.json()
                    results["server_root"]["has_proper_response"] = bool(data.get("message"))
        except Exception as e:
            results["server_root"] = {"error": str(e), "working": False}
        
        # 2. í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸
        try:
            start_time = time.time()
            async with self.session.get(f"{self.base_url}/health") as response:
                response_time = time.time() - start_time
                results["health_check"] = {
                    "status": response.status,
                    "working": response.status == 200,
                    "response_time": response_time
                }
                if response.status == 200:
                    health_data = await response.json()
                    results["health_check"].update({
                        "has_status": "status" in health_data,
                        "has_timestamp": "timestamp" in health_data,
                        "fast_response": response_time < 0.1
                    })
        except Exception as e:
            results["health_check"] = {"error": str(e), "working": False}
            self.critical_issues.append("í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ ì ‘ê·¼ ë¶ˆê°€")
        
        # 3. í‚¤ì›Œë“œ ë¶„ì„ API
        try:
            test_payload = {"keyword": "í”„ë¡œë•ì…˜í…ŒìŠ¤íŠ¸", "country": "KR", "max_results": 5}
            start_time = time.time()
            async with self.session.post(f"{self.base_url}/api/keywords/analyze", json=test_payload) as response:
                response_time = time.time() - start_time
                results["keyword_analysis"] = {
                    "status": response.status,
                    "working": response.status == 200,
                    "response_time": response_time
                }
                
                if response.status == 200:
                    data = await response.json()
                    results["keyword_analysis"].update({
                        "has_keyword": "keyword" in data,
                        "has_search_volume": "search_volume" in data,
                        "has_competition": "competition" in data,
                        "has_related_keywords": "related_keywords" in data,
                        "data_structure_valid": True
                    })
                elif response.status == 422:
                    # ê²€ì¦ ì˜¤ë¥˜ëŠ” ì •ìƒì ì¸ ë™ì‘
                    results["keyword_analysis"]["proper_validation"] = True
        except Exception as e:
            results["keyword_analysis"] = {"error": str(e), "working": False}
            self.critical_issues.append("í‚¤ì›Œë“œ ë¶„ì„ API ì˜¤ë¥˜")
        
        # 4. ì œëª© ìƒì„± API
        try:
            test_payload = {"keyword": "í”„ë¡œë•ì…˜í…ŒìŠ¤íŠ¸", "count": 3, "tone": "professional"}
            start_time = time.time()
            async with self.session.post(f"{self.base_url}/api/titles/generate", json=test_payload) as response:
                response_time = time.time() - start_time
                results["title_generation"] = {
                    "status": response.status,
                    "working": response.status == 200,
                    "response_time": response_time
                }
                
                if response.status == 200:
                    data = await response.json()
                    titles = data.get("titles", [])
                    results["title_generation"].update({
                        "has_titles": len(titles) > 0,
                        "titles_have_scores": all("score" in t for t in titles),
                        "proper_title_count": len(titles) == 3
                    })
        except Exception as e:
            results["title_generation"] = {"error": str(e), "working": False}
            self.warnings.append("ì œëª© ìƒì„± API ì ‘ê·¼ ë¬¸ì œ")
        
        # 5. ì½˜í…ì¸  ìƒì„± API
        try:
            test_payload = {
                "title": "í”„ë¡œë•ì…˜ í…ŒìŠ¤íŠ¸ìš© ì œëª©",
                "keyword": "í”„ë¡œë•ì…˜í…ŒìŠ¤íŠ¸",
                "length": "short"
            }
            start_time = time.time()
            async with self.session.post(f"{self.base_url}/api/content/generate", json=test_payload) as response:
                response_time = time.time() - start_time
                results["content_generation"] = {
                    "status": response.status,
                    "working": response.status == 200,
                    "response_time": response_time
                }
                
                if response.status == 200:
                    data = await response.json()
                    results["content_generation"].update({
                        "has_content": bool(data.get("content")),
                        "has_seo_score": "seo_score" in data,
                        "has_word_count": "word_count" in data,
                        "content_not_empty": len(data.get("content", "")) > 100
                    })
        except Exception as e:
            results["content_generation"] = {"error": str(e), "working": False}
            self.warnings.append("ì½˜í…ì¸  ìƒì„± API ì ‘ê·¼ ë¬¸ì œ")
        
        return results
    
    async def check_api_documentation(self) -> Dict[str, Any]:
        """API ë¬¸ì„œí™” ìƒíƒœ ê²€ì¦"""
        print("ğŸ“š API ë¬¸ì„œí™” ìƒíƒœ ê²€ì¦...")
        
        results = {}
        
        # 1. Swagger UI ì ‘ê·¼ì„±
        try:
            async with self.session.get(f"{self.base_url}/docs") as response:
                results["swagger_ui"] = {
                    "status": response.status,
                    "accessible": response.status == 200,
                    "content_type": response.headers.get("content-type", "")
                }
                
                if response.status == 200:
                    content = await response.text()
                    results["swagger_ui"]["has_swagger_content"] = "swagger" in content.lower()
        except Exception as e:
            results["swagger_ui"] = {"error": str(e), "accessible": False}
            self.warnings.append("Swagger UI ì ‘ê·¼ ë¶ˆê°€")
        
        # 2. OpenAPI ìŠ¤í‚¤ë§ˆ
        try:
            async with self.session.get(f"{self.base_url}/openapi.json") as response:
                results["openapi_schema"] = {
                    "status": response.status,
                    "accessible": response.status == 200
                }
                
                if response.status == 200:
                    schema = await response.json()
                    results["openapi_schema"].update({
                        "has_info": "info" in schema,
                        "has_paths": "paths" in schema and len(schema["paths"]) > 0,
                        "has_components": "components" in schema,
                        "valid_openapi": schema.get("openapi", "").startswith("3.")
                    })
        except Exception as e:
            results["openapi_schema"] = {"error": str(e), "accessible": False}
            self.warnings.append("OpenAPI ìŠ¤í‚¤ë§ˆ ì ‘ê·¼ ë¶ˆê°€")
        
        return results
    
    async def check_performance_requirements(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­ ê²€ì¦"""
        print("âš¡ ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­ ê²€ì¦...")
        
        results = {}
        
        # 1. ì‘ë‹µ ì‹œê°„ ë²¤ì¹˜ë§ˆí¬
        response_times = []
        
        for i in range(10):
            try:
                start_time = time.time()
                async with self.session.get(f"{self.base_url}/health") as response:
                    if response.status == 200:
                        response_times.append(time.time() - start_time)
                await asyncio.sleep(0.1)  # ì§§ì€ ê°„ê²©
            except:
                pass
        
        if response_times:
            avg_time = sum(response_times) / len(response_times)
            max_time = max(response_times)
            min_time = min(response_times)
            
            results["response_times"] = {
                "average": avg_time,
                "max": max_time,
                "min": min_time,
                "samples": len(response_times),
                "meets_sla": avg_time < 0.5,  # 500ms ì´ë‚´
                "consistent": max_time - min_time < 0.1  # ì¼ê´€ì„±
            }
            
            if avg_time > 1.0:
                self.warnings.append(f"í‰ê·  ì‘ë‹µ ì‹œê°„ì´ ëŠë¦¼: {avg_time:.3f}ì´ˆ")
        else:
            results["response_times"] = {"no_data": True}
            self.critical_issues.append("ì„±ëŠ¥ ì¸¡ì • ë¶ˆê°€")
        
        # 2. ë™ì‹œ ìš”ì²­ ì²˜ë¦¬
        try:
            concurrent_tasks = []
            start_time = time.time()
            
            for _ in range(5):
                task = self.session.get(f"{self.base_url}/health")
                concurrent_tasks.append(task)
            
            responses = await asyncio.gather(*concurrent_tasks, return_exceptions=True)
            total_time = time.time() - start_time
            
            successful = sum(1 for r in responses if not isinstance(r, Exception) and hasattr(r, 'status') and r.status == 200)
            
            results["concurrent_handling"] = {
                "total_requests": len(concurrent_tasks),
                "successful_requests": successful,
                "success_rate": successful / len(concurrent_tasks),
                "total_time": total_time,
                "handles_concurrent": successful >= 4  # 80% ì´ìƒ ì„±ê³µ
            }
            
            # ì‘ë‹µ ê°ì²´ ì •ë¦¬
            for r in responses:
                if hasattr(r, 'close'):
                    r.close()
                    
        except Exception as e:
            results["concurrent_handling"] = {"error": str(e)}
            self.warnings.append("ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        
        return results
    
    def check_file_structure(self) -> Dict[str, Any]:
        """íŒŒì¼ êµ¬ì¡° ë° ì„¤ì • ê²€ì¦"""
        print("ğŸ“ íŒŒì¼ êµ¬ì¡° ë° ì„¤ì • ê²€ì¦...")
        
        results = {}
        project_root = Path("/mnt/e/project/test-blogauto-project")
        
        # 1. í•„ìˆ˜ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€
        essential_files = {
            "README.md": project_root / "README.md",
            ".env.example": project_root / ".env.example",
            "requirements.txt": project_root / "backend" / "requirements.txt",
            "docker-compose.yml": project_root / "docker-compose.yml",
            "API ë¬¸ì„œ": project_root / "docs" / "api-docs.md",
            "ë°°í¬ ê°€ì´ë“œ": project_root / "docs" / "deployment-guide.md",
            "ë³´ì•ˆ ê°€ì´ë“œ": project_root / "docs" / "security-guide.md"
        }
        
        file_checks = {}
        missing_files = []
        
        for file_name, file_path in essential_files.items():
            exists = file_path.exists()
            file_checks[file_name] = {
                "exists": exists,
                "path": str(file_path)
            }
            
            if exists and file_path.is_file():
                try:
                    file_size = file_path.stat().st_size
                    file_checks[file_name]["size"] = file_size
                    file_checks[file_name]["not_empty"] = file_size > 100
                except:
                    file_checks[file_name]["size_check_failed"] = True
            else:
                missing_files.append(file_name)
        
        results["essential_files"] = file_checks
        results["missing_files"] = missing_files
        
        if missing_files:
            self.warnings.extend([f"í•„ìˆ˜ íŒŒì¼ ëˆ„ë½: {f}" for f in missing_files])
        
        # 2. ì„¤ì • íŒŒì¼ ê²€ì¦
        env_example_path = project_root / ".env.example"
        if env_example_path.exists():
            try:
                with open(env_example_path, 'r', encoding='utf-8') as f:
                    env_content = f.read()
                
                required_vars = [
                    "OPENAI_API_KEY", "DATABASE_URL", "SECRET_KEY", 
                    "MASTER_PASSWORD", "REDIS_HOST"
                ]
                
                env_check = {}
                for var in required_vars:
                    env_check[var] = var in env_content
                
                results["env_template"] = {
                    "exists": True,
                    "required_vars": env_check,
                    "all_vars_present": all(env_check.values())
                }
                
                if not all(env_check.values()):
                    missing_vars = [var for var, present in env_check.items() if not present]
                    self.warnings.append(f"í™˜ê²½ ë³€ìˆ˜ í…œí”Œë¦¿ ëˆ„ë½: {', '.join(missing_vars)}")
                    
            except Exception as e:
                results["env_template"] = {"error": str(e)}
        
        # 3. ë¬¸ì„œ í’ˆì§ˆ ê²€ì¦
        docs_dir = project_root / "docs"
        if docs_dir.exists():
            doc_files = list(docs_dir.glob("*.md"))
            results["documentation"] = {
                "docs_count": len(doc_files),
                "has_multiple_docs": len(doc_files) >= 5,
                "doc_files": [f.name for f in doc_files]
            }
        else:
            results["documentation"] = {"docs_dir_missing": True}
            self.warnings.append("ë¬¸ì„œ ë””ë ‰í† ë¦¬ ëˆ„ë½")
        
        return results
    
    def check_security_configuration(self) -> Dict[str, Any]:
        """ë³´ì•ˆ ì„¤ì • ê²€ì¦"""
        print("ğŸ”’ ë³´ì•ˆ ì„¤ì • ê²€ì¦...")
        
        results = {}
        
        # 1. í™˜ê²½ ë³€ìˆ˜ ë³´ì•ˆ
        security_checks = {
            "env_file_not_in_git": True,  # .env íŒŒì¼ì´ Gitì— í¬í•¨ë˜ì§€ ì•Šì•˜ëŠ”ì§€
            "example_file_exists": Path("/mnt/e/project/test-blogauto-project/.env.example").exists(),
            "gitignore_exists": Path("/mnt/e/project/test-blogauto-project/.gitignore").exists()
        }
        
        # 2. ê¸°ë³¸ ë³´ì•ˆ ì„¤ì •
        try:
            gitignore_path = Path("/mnt/e/project/test-blogauto-project/.gitignore")
            if gitignore_path.exists():
                with open(gitignore_path, 'r') as f:
                    gitignore_content = f.read()
                
                security_checks.update({
                    "env_in_gitignore": ".env" in gitignore_content,
                    "logs_ignored": "*.log" in gitignore_content,
                    "cache_ignored": "__pycache__" in gitignore_content
                })
        except:
            pass
        
        results["security_files"] = security_checks
        
        # ë³´ì•ˆ ë¬¸ì œ ì²´í¬
        security_issues = []
        if not security_checks.get("example_file_exists"):
            security_issues.append("í™˜ê²½ ë³€ìˆ˜ í…œí”Œë¦¿ íŒŒì¼ ëˆ„ë½")
        if not security_checks.get("env_in_gitignore"):
            security_issues.append(".env íŒŒì¼ì´ gitignoreì— ì—†ìŒ")
        
        if security_issues:
            self.warnings.extend(security_issues)
        
        results["security_score"] = sum(security_checks.values()) / len(security_checks) * 100
        
        return results
    
    async def run_production_readiness_check(self) -> Dict[str, Any]:
        """í”„ë¡œë•ì…˜ ì¤€ë¹„ë„ ì¢…í•© ê²€ì¦"""
        print("ğŸš€ BlogAuto í”„ë¡œë•ì…˜ ë°°í¬ ì¤€ë¹„ë„ ìµœì¢… ê²€ì¦")
        print("=" * 70)
        
        start_time = time.time()
        
        comprehensive_results = {
            "check_info": {
                "timestamp": datetime.now().isoformat(),
                "checker_version": "1.0.0",
                "check_type": "production_readiness"
            },
            "results": {},
            "summary": {}
        }
        
        try:
            # 1. API ê¸°ëŠ¥ ê²€ì¦
            comprehensive_results["results"]["api_functionality"] = await self.check_api_functionality()
            
            # 2. API ë¬¸ì„œí™” ê²€ì¦
            comprehensive_results["results"]["api_documentation"] = await self.check_api_documentation()
            
            # 3. ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­ ê²€ì¦
            comprehensive_results["results"]["performance"] = await self.check_performance_requirements()
            
            # 4. íŒŒì¼ êµ¬ì¡° ê²€ì¦
            comprehensive_results["results"]["file_structure"] = self.check_file_structure()
            
            # 5. ë³´ì•ˆ ì„¤ì • ê²€ì¦
            comprehensive_results["results"]["security"] = self.check_security_configuration()
            
            # ì´ ê²€ì¦ ì‹œê°„
            comprehensive_results["check_info"]["duration"] = time.time() - start_time
            
            # ì¢…í•© í‰ê°€
            comprehensive_results["summary"] = self._generate_production_summary(
                comprehensive_results["results"]
            )
            
        except Exception as e:
            comprehensive_results["error"] = str(e)
            comprehensive_results["check_info"]["duration"] = time.time() - start_time
        
        return comprehensive_results
    
    def _generate_production_summary(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """í”„ë¡œë•ì…˜ ì¤€ë¹„ë„ ì¢…í•© í‰ê°€"""
        summary = {
            "overall_readiness": "unknown",
            "readiness_score": 0,
            "critical_systems_ready": 0,
            "total_critical_systems": 5,  # API, ë¬¸ì„œ, ì„±ëŠ¥, íŒŒì¼, ë³´ì•ˆ
            "issues_summary": {
                "critical": len(self.critical_issues),
                "warnings": len(self.warnings),
                "total": len(self.critical_issues) + len(self.warnings)
            },
            "recommendations": self.recommendations.copy(),
            "deployment_blockers": self.critical_issues.copy(),
            "improvement_suggestions": self.warnings.copy()
        }
        
        # ê° ì‹œìŠ¤í…œ ì¤€ë¹„ë„ í‰ê°€
        system_scores = {}
        
        # 1. API ê¸°ëŠ¥ í‰ê°€
        api_func = results.get("api_functionality", {})
        api_score = 0
        api_working_count = 0
        critical_apis = ["server_root", "health_check", "keyword_analysis"]
        
        for api in critical_apis:
            if api in api_func and api_func[api].get("working", False):
                api_working_count += 1
        
        api_score = (api_working_count / len(critical_apis)) * 100
        system_scores["api_functionality"] = api_score
        
        if api_score >= 80:
            summary["critical_systems_ready"] += 1
        
        # 2. ë¬¸ì„œí™” í‰ê°€
        docs = results.get("api_documentation", {})
        docs_score = 0
        
        if docs.get("swagger_ui", {}).get("accessible", False):
            docs_score += 50
        if docs.get("openapi_schema", {}).get("accessible", False):
            docs_score += 50
        
        system_scores["documentation"] = docs_score
        
        if docs_score >= 80:
            summary["critical_systems_ready"] += 1
        
        # 3. ì„±ëŠ¥ í‰ê°€
        perf = results.get("performance", {})
        perf_score = 0
        
        response_times = perf.get("response_times", {})
        if response_times.get("meets_sla", False):
            perf_score += 60
        if response_times.get("consistent", False):
            perf_score += 40
        
        system_scores["performance"] = perf_score
        
        if perf_score >= 60:
            summary["critical_systems_ready"] += 1
        
        # 4. íŒŒì¼ êµ¬ì¡° í‰ê°€
        files = results.get("file_structure", {})
        files_score = 0
        
        missing_files = len(files.get("missing_files", []))
        if missing_files == 0:
            files_score = 100
        elif missing_files <= 2:
            files_score = 70
        else:
            files_score = 40
        
        system_scores["file_structure"] = files_score
        
        if files_score >= 70:
            summary["critical_systems_ready"] += 1
        
        # 5. ë³´ì•ˆ í‰ê°€
        security = results.get("security", {})
        security_score = security.get("security_score", 0)
        system_scores["security"] = security_score
        
        if security_score >= 80:
            summary["critical_systems_ready"] += 1
        
        # ì „ì²´ ì ìˆ˜ ê³„ì‚°
        summary["readiness_score"] = sum(system_scores.values()) / len(system_scores)
        summary["system_scores"] = system_scores
        
        # ì „ì²´ ì¤€ë¹„ë„ ê²°ì •
        if summary["critical_systems_ready"] >= 5 and len(self.critical_issues) == 0:
            summary["overall_readiness"] = "production_ready"
            summary["recommendations"].append("âœ… í”„ë¡œë•ì…˜ ë°°í¬ ì¤€ë¹„ ì™„ë£Œ!")
        elif summary["critical_systems_ready"] >= 4 and len(self.critical_issues) <= 1:
            summary["overall_readiness"] = "near_ready"
            summary["recommendations"].append("ğŸŸ¡ ê²½ë¯¸í•œ ìˆ˜ì • í›„ ë°°í¬ ê°€ëŠ¥")
        elif summary["critical_systems_ready"] >= 3:
            summary["overall_readiness"] = "needs_improvement"
            summary["recommendations"].append("ğŸŸ  ì¼ë¶€ ê°œì„  í›„ ë°°í¬ ê¶Œì¥")
        else:
            summary["overall_readiness"] = "not_ready"
            summary["recommendations"].append("ğŸ”´ ì£¼ìš” ë¬¸ì œ í•´ê²° í›„ ì¬ê²€í†  í•„ìš”")
        
        return summary

def print_production_readiness_report(results: Dict[str, Any]):
    """í”„ë¡œë•ì…˜ ì¤€ë¹„ë„ ë³´ê³ ì„œ ì¶œë ¥"""
    print("\n" + "=" * 70)
    print("ğŸ“Š BlogAuto í”„ë¡œë•ì…˜ ë°°í¬ ì¤€ë¹„ë„ ìµœì¢… ë³´ê³ ì„œ")
    print("=" * 70)
    
    # ê¸°ë³¸ ì •ë³´
    check_info = results.get("check_info", {})
    print(f"ğŸ• ê²€ì¦ ì‹œê°„: {check_info.get('timestamp', 'unknown')}")
    print(f"â±ï¸ ì†Œìš” ì‹œê°„: {check_info.get('duration', 0):.2f}ì´ˆ")
    
    # ì¢…í•© í‰ê°€
    summary = results.get("summary", {})
    readiness = summary.get("overall_readiness", "unknown")
    score = summary.get("readiness_score", 0)
    
    readiness_emojis = {
        "production_ready": "ğŸŸ¢",
        "near_ready": "ğŸŸ¡",
        "needs_improvement": "ğŸŸ ", 
        "not_ready": "ğŸ”´"
    }
    
    print(f"\nğŸ¯ ì „ì²´ ì¤€ë¹„ë„: {readiness_emojis.get(readiness, 'â“')} {readiness.upper()}")
    print(f"ğŸ“ˆ ì¤€ë¹„ë„ ì ìˆ˜: {score:.1f}/100")
    print(f"â­ í•µì‹¬ ì‹œìŠ¤í…œ ì¤€ë¹„: {summary.get('critical_systems_ready', 0)}/{summary.get('total_critical_systems', 5)}")
    
    # ì‹œìŠ¤í…œë³„ ì ìˆ˜
    system_scores = summary.get("system_scores", {})
    print(f"\nğŸ“‹ ì‹œìŠ¤í…œë³„ ì¤€ë¹„ë„:")
    
    for system, score in system_scores.items():
        emoji = "âœ…" if score >= 80 else "âš ï¸" if score >= 60 else "âŒ"
        system_name = system.replace("_", " ").title()
        print(f"   {emoji} {system_name}: {score:.1f}%")
    
    # API ê¸°ëŠ¥ ìƒì„¸
    api_results = results.get("results", {}).get("api_functionality", {})
    print(f"\nğŸ¯ API ê¸°ëŠ¥ ìƒíƒœ:")
    
    api_functions = {
        "server_root": "ì„œë²„ ë£¨íŠ¸",
        "health_check": "í—¬ìŠ¤ì²´í¬",
        "keyword_analysis": "í‚¤ì›Œë“œ ë¶„ì„",
        "title_generation": "ì œëª© ìƒì„±",
        "content_generation": "ì½˜í…ì¸  ìƒì„±"
    }
    
    for api_key, api_name in api_functions.items():
        if api_key in api_results:
            api_data = api_results[api_key]
            working = api_data.get("working", False)
            response_time = api_data.get("response_time", 0)
            status = "âœ…" if working else "âŒ"
            print(f"   {status} {api_name}: {response_time:.3f}ì´ˆ")
    
    # ì„±ëŠ¥ ë©”íŠ¸ë¦­
    perf_results = results.get("results", {}).get("performance", {})
    response_times = perf_results.get("response_times", {})
    
    if response_times and "average" in response_times:
        print(f"\nâš¡ ì„±ëŠ¥ ë©”íŠ¸ë¦­:")
        print(f"   ğŸ“Š í‰ê·  ì‘ë‹µ ì‹œê°„: {response_times['average']:.3f}ì´ˆ")
        print(f"   ğŸ“Š ìµœëŒ€ ì‘ë‹µ ì‹œê°„: {response_times['max']:.3f}ì´ˆ")
        print(f"   ğŸ“Š SLA ì¤€ìˆ˜: {'âœ…' if response_times.get('meets_sla', False) else 'âŒ'}")
    
    # ì´ìŠˆ ìš”ì•½
    issues = summary.get("issues_summary", {})
    print(f"\nâš ï¸ ë°œê²¬ëœ ì´ìŠˆ:")
    print(f"   ğŸ”´ ì¤‘ìš” ì´ìŠˆ: {issues.get('critical', 0)}ê°œ")
    print(f"   ğŸŸ¡ ê²½ê³  ì‚¬í•­: {issues.get('warnings', 0)}ê°œ")
    
    # ë°°í¬ ì°¨ë‹¨ ìš”ì†Œ
    blockers = summary.get("deployment_blockers", [])
    if blockers:
        print(f"\nğŸš« ë°°í¬ ì°¨ë‹¨ ìš”ì†Œ:")
        for blocker in blockers:
            print(f"   â€¢ {blocker}")
    
    # ê°œì„  ì œì•ˆ
    suggestions = summary.get("improvement_suggestions", [])
    if suggestions:
        print(f"\nğŸ’¡ ê°œì„  ì œì•ˆì‚¬í•­:")
        for suggestion in suggestions[:5]:  # ìƒìœ„ 5ê°œë§Œ
            print(f"   â€¢ {suggestion}")
    
    # ê¶Œì¥ì‚¬í•­
    recommendations = summary.get("recommendations", [])
    if recommendations:
        print(f"\nğŸ¯ ìµœì¢… ê¶Œì¥ì‚¬í•­:")
        for rec in recommendations:
            print(f"   â€¢ {rec}")

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    async with ProductionReadinessChecker() as checker:
        results = await checker.run_production_readiness_check()
        
        # ê²°ê³¼ ì¶œë ¥
        print_production_readiness_report(results)
        
        # ê²°ê³¼ íŒŒì¼ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"/mnt/e/project/test-blogauto-project/production_readiness_report_{timestamp}.json"
        
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ ìƒì„¸ ë³´ê³ ì„œê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ìµœì¢… ìƒíƒœ ë°˜í™˜
        readiness = results.get("summary", {}).get("overall_readiness", "not_ready")
        return 0 if readiness in ["production_ready", "near_ready"] else 1

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)